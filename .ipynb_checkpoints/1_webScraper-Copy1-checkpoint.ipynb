{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aff28e05-931c-4743-8ffe-15562cbf8abb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3480eeb5-4e30-4596-9632-ecdda9f2202f",
   "metadata": {},
   "source": [
    "## Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21d0bc01-2a0b-47d1-a09b-0849993e3db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the web pages linked to the input url\n",
    "def create_list_of_links(url):\n",
    "    #url = input('Ingrese una pagina de su interés')\n",
    "    reqs = requests.get(url)\n",
    "    soup = BeautifulSoup(reqs.text, 'html.parser')               \n",
    " \n",
    "    urls = []\n",
    "    diccionario = {}\n",
    "    \n",
    "    for link in soup.find_all('a'):\n",
    "        urls.append(link.get('href'))\n",
    "    lista = list(diccionario.fromkeys(urls))\n",
    "    lista.remove(None)\n",
    "    \n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e45a8629-db0f-45f8-9a6d-aeb98315c6a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "listA = create_list_of_links('https://en.wikipedia.org/wiki/2022_FIFA_World_Cup_squads')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d284fbb-d6e8-4985-9c09-fe9b99257d3c",
   "metadata": {},
   "source": [
    " - We need to list all the web pages which contain __'/wiki/xxxx_FIFA_World_Cup_squads'__ , where xxxx represents a year. Web [root](https://en.wikipedia.org) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c39ec7-9f22-4fba-91c7-dfe5dcbe19c5",
   "metadata": {},
   "source": [
    "Let's filter the urls we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0be02ea8-eb35-42d9-99dd-916539b35cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sudDirsStringLength = len('/wiki/1930_FIFA_World_Cup_squads')  # we could try to filter by the subdirectories string length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecd2910b-e8ad-4eb9-bb58-bf5a572ccde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "subString = 'squads'                   # keyword\n",
    "rootURL = 'https://en.wikipedia.org'   # website root address"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499c3015-233e-4064-948c-845011822ae7",
   "metadata": {},
   "source": [
    "The function `filter_list` receives three parameters. The first is a list of all the websites we got after crawling. The second, a substring with a keyword shared by all wanted urls. And the third is the website root address. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b86ba11-b913-410e-8a0f-b137865e841e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_list(aList, mySubString,rootAddress):\n",
    "    requiredURLS = []\n",
    "    for element in aList:\n",
    "        if ((subString in element) and(len(element)==sudDirsStringLength)):\n",
    "            desiredURL = rootAddress + element\n",
    "            requiredURLS.append(desiredURL)\n",
    "    return requiredURLS       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afce266-959f-4336-b6ba-b67b0f575a92",
   "metadata": {},
   "source": [
    "## Functions to process the gathered data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d29a7f-86ad-4cc2-be71-cf823fc3bd04",
   "metadata": {},
   "source": [
    "The following function, `get_soup`, receives the filtered url list plus an index and returns a BeautifulSoup object which encloses all the url parsed code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e543ace1-c364-462c-a310-2c8a6ce1a8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(WorldCupsList, index):   \n",
    "    \n",
    "    page = requests.get(WorldCupsList[index]).text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fe0d87-3199-4208-a0c7-cf770747fd44",
   "metadata": {},
   "source": [
    "The function `get_total_players_in_squad` counts all the rows of the national teams tables; or what\n",
    "is the same, all the players belonging to a given team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55adea2c-8755-41ad-9c8a-608a3b624074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_players_in_squad(mySoup, index):\n",
    "    totalRows = len(mySoup.find_all('table', class_=\"sortable wikitable plainrowheaders\")[index].find_all('tr')[1::1])\n",
    "    return totalRows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23936e5-b4e6-46bf-bfb0-e2e5cead25cd",
   "metadata": {},
   "source": [
    "The tables we've found have an odd and confusing structure. They used different tags to create the columns instead of using the same. The 'Pos.' column is in a \"th\" tag, while the rest are inside a \"td\" tag. This fact has complicated our work a little bit. So, we'll have to create two separate counts, one for each type of tag, because we'll have to reshape these tables later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfff2c00-f2c9-4cab-8dad-4c364659c1c6",
   "metadata": {},
   "source": [
    "The function `count_columns_in_tags` counts and discriminates tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11d6a8fa-277d-4e60-a3fe-2e27a32800ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_columns_in_tags(aTable):\n",
    "    # Navigate downwards in the data tree\n",
    "    tbodyContents = aTable.tbody.contents   \n",
    "    # The 3rd element corresponds to the 1st data row. Once in there, we can start counting the 'th' tags with relevant data\n",
    "    amountOfThTags  = len(tbodyContents[2].find_all(\"th\")) \n",
    "    # and also the 'td' tags\n",
    "    totalTdTags = len(tbodyContents[2].find_all('td'))      # number of 'td' tags > number of 'th' tags \n",
    "    \n",
    "    return (totalTdTags, amountOfThTags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd67500-63bb-45ce-ae42-bc17be8daacb",
   "metadata": {},
   "source": [
    "As Pandas doesn't fill the column named \"Date of birth\" we'll work around this issue as follows:\n",
    "Firstly, we'll use the function below, `get_list_of_birthdays`, to get a list of each footballer's birthday.\n",
    "Secondly, we'll convert the table to a DataFrame.\n",
    "Finally, we'll add a new column to the DataFrame, and set the values with each corresponding element in the list of birthdays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10f6378e-84de-4c91-8d0f-cc8b0936f24c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_list_of_birthdays(aTable, number):\n",
    "    listOfBirthDays = []\n",
    "    offset = count_columns_in_tags(aTable)[0]\n",
    "    contador = 0\n",
    "    for i in range(number):\n",
    "        position = 2 + (contador*offset)    # The date of birth is in the fourth column so our initial position should be at the \n",
    "        try:                                # index [3], not[2], but remember that there is a 'th' tag in the middle of the 'td' \n",
    "                                            # tags. So our starting point was moved one to the left.\n",
    "            data = aTable.find_all('td')      # find all the 'td' tags that store the data\n",
    "            dateOfBirth = data[position]       \n",
    "            listOfBirthDays.append(dateOfBirth.span.text)\n",
    "        except (IndexError, AttributeError):\n",
    "            listOfBirthDays.append(dateOfBirth.text)\n",
    "        contador +=1\n",
    "    return listOfBirthDays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a129c7-2999-4277-982b-acc7f9c7af91",
   "metadata": {},
   "source": [
    "In the original tables, there is a column with the player's club data, this piece of data is essential, but also we'd like to know the country where a given footballer had been playing until the World Cup kick-off. In each of their cells there is a flag icon that holds the name of the country to which that club belongs. We'll make use of the `get_list_of_clubs_federations` function to extract the country related to each club."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "021b5259-24a2-47b8-8515-ff9b85efd9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_clubs_federations(aTable, number):\n",
    "    listOfClubsFederations = []\n",
    "    offset = count_columns_in_tags(aTable)[0]\n",
    "    contador = 0\n",
    "    for i in range(number):\n",
    "        position = (offset -1) + (contador*offset) # number of 'td' tags columns - number of 'th' tags columns\n",
    "        data = aTable.find_all('td')  \n",
    "        clubFederation = data[position] \n",
    "        try:\n",
    "             \n",
    "            listOfClubsFederations.append(clubFederation.a.img.get(\"alt\"))\n",
    "        except (IndexError, AttributeError):\n",
    "            if clubFederation.find(class_=\"flagicon\"):\n",
    "                listOfClubsFederations.append(clubFederation.span.img.get(\"alt\"))\n",
    "            else:\n",
    "                listOfClubsFederations.append(np.nan)\n",
    "        contador +=1\n",
    "    return listOfClubsFederations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7254f99-d56f-4801-b802-aa0e6e21e965",
   "metadata": {},
   "source": [
    "The function `get_listed_national_teams` gets the names of the countries from the 'H3' or 'H2' tags(depending on the web page code) located above each squad's table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5f59dad-ed8d-4642-9f7c-2d74e5abc8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_listed_national_teams(resultSet, numberOfSquads):\n",
    "    listNationalTeams=[]\n",
    "    for i in range(numberOfSquads):\n",
    "        try:\n",
    "            listNationalTeams.append(resultSet[i].span.text)\n",
    "        except(AttributeError):\n",
    "            listNationalTeams.append(resultSet[i].text)\n",
    "    return listNationalTeams  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33333103-9c01-4170-9789-fc24f804566b",
   "metadata": {},
   "source": [
    "####  Functions to deal with additional tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eed70f0-a48d-4476-8cd7-ba4c6928d1d6",
   "metadata": {},
   "source": [
    "The following function `exists_replacement_table` searches inside the tables containing squads. If it finds a small one, that means it found an additional table with the data of a replacement player in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a0002a8-2f42-43fb-bd6d-6801be9d0e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exists_replacement_table(squadsTables):\n",
    "    for i in range(len(squadsTables)):\n",
    "        if len(squadsTables[i].find_all('tr')[1::1]) < 4:\n",
    "            return True\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f409953f-678f-40fe-b714-84846b3be2b8",
   "metadata": {},
   "source": [
    "If there are replacement players tables the function `report_additional_tables` will catch and list them, for further treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59c17980-0a5b-4f33-b5be-cc91aa773c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_additional_tables(worldCup, squadsTables, reportingList):\n",
    "    for i in range(len(squadsTables)):\n",
    "        if len(squadsTables[i].find_all('tr')[1::1]) < 4:\n",
    "            reportingList.append((worldCup,i))\n",
    "    return reportingList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b871df91-2ceb-4bc8-ac32-db2d9b43e1ff",
   "metadata": {},
   "source": [
    "Once we have found additional tables we'll need to set them aside. That's what `take_off_additional_tables` does, by renaming their css class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7deddef4-032e-4a2f-a573-2d7f6becad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_off_additional_tables(aSoup, squadsTables):\n",
    "    for i in range(len(squadsTables)):\n",
    "        if len(squadsTables[i].find_all('tr')[1::1]) < 4:\n",
    "\n",
    "            # change the css class of the additional tables to differentiate them from the ones with the whole team data.\n",
    "            additionalTable = squadsTables[i]\n",
    "            additionalTable['class'] = 'replacement'\n",
    "\n",
    "    return soup.find_all('table', class_=\"sortable wikitable plainrowheaders\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4e70aa-2838-445d-b554-d7d38d56fd70",
   "metadata": {},
   "source": [
    "## Added data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cdb8b13-eb1c-48b6-8214-0f4bb4de73b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all the years in which a World Cup was played.\n",
    "worldCupYears = []\n",
    "for i in range(1930,2023,4):\n",
    "    if i <= 1938:\n",
    "        worldCupYears.append(i)\n",
    "    elif ((i > 1938) & (i <1950)):\n",
    "        pass\n",
    "    else:\n",
    "        worldCupYears.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ab02109",
   "metadata": {},
   "outputs": [],
   "source": [
    "wcKickOffDates = ['1930-07-17','1934-05-27','1938-06-04','1950-06-24','1954-06-16','1958-06-08','1962-05-30','1966-07-11',\n",
    "                    '1970-05-31','1974-06-13','1978-06-01','1982-06-13','1986-05-31','1990-06-08','1994-06-17','1998-06-10',\n",
    "                    '2002-05-31','2006-06-09','2010-06-11','2014-06-12','2018-06-14','2022-11-20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66620b44-b4e5-4bb5-8774-76d6d7b5ca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to collect and identify all the additional players tables,\n",
    "# that could break our code.\n",
    "additionalTablesList = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77428762-ba57-4fdb-aed9-63bb16fe76e0",
   "metadata": {},
   "source": [
    "## Files Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "379397dd-5b62-4dd8-9f8a-3aecb961c891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c49314a4-5fc9-4e23-b6f2-2136ba805015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directories_tree(listOfWCYears):\n",
    "    \n",
    "    for i in range(len(listOfWCYears)):\n",
    "        year = str(listOfWCYears[i])\n",
    "        os.makedirs(f'dataSets\\\\{year}_world_cup', exist_ok=True)  # makes a new directory      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6297107c-2916-4e9c-aae6-cbb08a4c6326",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (path.exists('dataSets') == False):\n",
    "    create_directories_tree(worldCupYears)\n",
    "if (path.exists('dataSets\\\\1930_world_cup')) & (len(os.listdir('dataSets')) < (len(worldCupYears))):\n",
    "    create_directories_tree(worldCupYears)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f6be93f-9b01-4c52-ae0a-5989acda9485",
   "metadata": {},
   "outputs": [],
   "source": [
    "listdir = os.listdir('dataSets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bee1ac-dc92-438f-bd32-7dca158c3f89",
   "metadata": {},
   "source": [
    "## Run the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce2d7bd5-1d58-420b-9374-885554b03823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 2s\n",
      "Wall time: 3min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "squadsHystorical = filter_list(listA,subString, rootURL)\n",
    "for j in range(len(squadsHystorical)):\n",
    "    \n",
    "    soup = get_soup(squadsHystorical, j)\n",
    "    allSquadsTables = soup.find_all('table', class_=\"sortable wikitable plainrowheaders\")\n",
    "    wcKickOff = wcKickOffDates[j]\n",
    "    \n",
    "    if exists_replacement_table(allSquadsTables):\n",
    "        report_additional_tables(worldCupYears[j],allSquadsTables, additionalTablesList)\n",
    "        take_off_additional_tables(soup, allSquadsTables)\n",
    "        allSquadsTables = soup.find_all('table', class_=\"sortable wikitable plainrowheaders\")\n",
    "    \n",
    "    totalSquads = len(soup.find_all('table',{'class': 'sortable wikitable plainrowheaders'}))\n",
    "    listH3CountryNames = soup.find_all(\"h3\", limit = totalSquads)\n",
    "    listH2CountryNames = soup.find_all(\"span\", class_=\"mw-headline\", limit = totalSquads)\n",
    "    allSquadsTables = soup.find_all('table', class_=\"sortable wikitable plainrowheaders\")\n",
    "\n",
    "    for i in range(totalSquads):\n",
    "    \n",
    "        myTable = allSquadsTables[i]\n",
    "        totalRows =  get_total_players_in_squad(soup, i) \n",
    "    \n",
    "        tagsTuple = count_columns_in_tags(myTable)\n",
    "    \n",
    "        # get the number of columns inside the 'td' tags\n",
    "        columnsAsTdTags = tagsTuple[0]\n",
    "            \n",
    "        try:\n",
    "            listNationalTeams= get_listed_national_teams(listH3CountryNames, totalSquads)\n",
    "        except (IndexError):\n",
    "            listNationalTeams= get_listed_national_teams(listH2CountryNames, totalSquads)\n",
    "    \n",
    "        listOfBirthDays =  get_list_of_birthdays(myTable, totalRows)\n",
    "        listOfClubsOrigin = get_list_of_clubs_federations(myTable, totalRows)\n",
    "        \n",
    "        df = create_a_dataframe(str(myTable), listOfClubsOrigin, listOfBirthDays, wcKickOff, listNationalTeams[i])\n",
    "        \n",
    "#         df = pd.read_html(str(myTable))\n",
    "#         df = pd.concat(df)\n",
    "#         ########################################################### WCKickOff Parámetro día para el dataframe\n",
    "#         if 'Goals' not in df.columns:\n",
    "#             df.insert(5, 'Goals', np.nan)\n",
    "        \n",
    "#         df['Club Origin'] = listOfClubsOrigin\n",
    "#         df['Date of birth (age)'] = listOfBirthDays\n",
    "        \n",
    "#         df.insert(0, 'National Team', listNationalTeams[i])\n",
    "#         players = df.pop('Player')\n",
    "#         df.insert(0,'Player', players) \n",
    "        \n",
    "        nameFile = (f'{worldCupYears[j]}_{listNationalTeams[i]}')           \n",
    "    \n",
    "        df.to_csv(f'dataSets\\\\{listdir[j]}\\\\{nameFile}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e1f5cb0-c894-4529-8f31-82a2f0e43350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1990, 5), (1990, 23)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additionalTablesList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cefda6c9-76a6-410f-bec0-cad2e93ab464",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f'errors', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e07de768-8ef7-4307-b2c1-3a091ad33afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"errors\\\\additionalTables.txt\", \"w\") as output:\n",
    "    output.write(str(additionalTablesList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0db24a00-2af7-4d15-9fbd-dd88e4c7a495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1990, 5), (1990, 23)]\n"
     ]
    }
   ],
   "source": [
    "f = open(\"errors\\\\additionalTables.txt\", \"r\")\n",
    "print(f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f286f42d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
